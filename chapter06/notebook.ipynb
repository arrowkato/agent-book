{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Advanced RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "# google colab 用なのでコメントアウト。\n",
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\"\n",
    "# os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. ハンズオンの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab 用なのでコメントアウト。uvを使っている場合はインストール済み\n",
    "# !pip install langchain-core==0.3.0 langchain-openai==0.2.0 \\\n",
    "#     langchain-community==0.3.0 GitPython==3.1.43 \\\n",
    "#     langchain-chroma==0.1.4 tavily-python==0.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 事前に .env ファイルを作って、OPENAI_API_KEY, LANGCHAIN_API_KEY, TAVILY_API_KEY, COHERE_API_KEY などを設定してください\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# コンテナ内で git を使う場合は、git checkout時にエラーにならないように以下を実行してください\n",
    "!git config --global --add safe.directory /workspaces/agent-book/chapter06/langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能を提供しています。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを使用して、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\\n\\n2. **生産化**: LangSmithを使用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\\n\\nLangChainは、以下のオープンソースライブラリで構成されています：\\n- `langchain-core`: 基本的な抽象化とLangChain表現言語。\\n- `langchain-community`: サードパーティの統合。\\n- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するための開発者プラットフォーム。\\n\\nLangChainは、PythonとJavaScriptの両方のライブラリがあり、特にPythonのLangChainライブラリに焦点を当てたドキュメントが提供されています。'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever,\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. 検索クエリの工夫\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE（Hypothetical Document Embeddings）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothetical_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "次の質問に回答する一文を書いてください。\n",
    "\n",
    "質問: {question}\n",
    "\"\"\")\n",
    "\n",
    "hypothetical_chain = hypothetical_prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能を提供しています。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを利用して、状態を持つエージェントを構築することができます。\\n\\n2. **生産化**: LangSmithを使用して、チェーンを検査、監視、評価し、アプリケーションを継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイメント**: LangGraphアプリケーションを本番環境向けのAPIやアシスタントに変換することができます。\\n\\nLangChainは、標準化されたコンポーネントインターフェース、オーケストレーション、可観測性と評価といった主要なニーズに応えることを目指しています。これにより、開発者は異なるプロバイダーを簡単に切り替えたり、複雑なアプリケーションを構築したりすることが可能になります。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyde_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": hypothetical_chain | retriever,\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "hyde_rag_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 複数の検索クエリの生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class QueryGenerationOutput(BaseModel):\n",
    "    queries: list[str] = Field(..., description=\"検索クエリのリスト\")\n",
    "\n",
    "\n",
    "query_generation_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "質問に対してベクターデータベースから関連文書を検索するために、\n",
    "3つの異なる検索クエリを生成してください。\n",
    "距離ベースの類似性検索の限界を克服するために、\n",
    "ユーザーの質問に対して複数の視点を提供することが目標です。\n",
    "\n",
    "質問: {question}\n",
    "\"\"\")\n",
    "\n",
    "query_generation_chain = (\n",
    "    query_generation_prompt\n",
    "    | model.with_structured_output(QueryGenerationOutput)\n",
    "    | (lambda x: x.queries)\n",
    ")  # fmt: skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能があります。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロック、コンポーネント、サードパーティ統合を使用してアプリケーションを構築できます。また、LangGraphを使用して、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\\n\\n2. **生産化**: LangSmithを利用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\\n\\nLangChainは、以下のオープンソースライブラリで構成されています：\\n- `langchain-core`: 基本的な抽象化とLangChain表現言語（LCEL）。\\n- `langchain-community`: サードパーティ統合。\\n- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するための開発者プラットフォーム。\\n\\nLangChainは、開発者がアプリケーションを簡単に構築できるように設計されており、さまざまなコンポーネントを組み合わせて使用することができます。'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_query_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": query_generation_chain | retriever.map(),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")  # fmt: skip\n",
    "\n",
    "multi_query_rag_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4. 検索後の工夫\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Fusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(\n",
    "    retriever_outputs: list[list[Document]],\n",
    "    k: int = 60,  # k は、ハイパーパラメータ\n",
    ") -> list[str]:\n",
    "    # 各ドキュメントのコンテンツ (文字列) とそのスコアの対応を保持する辞書を準備\n",
    "    content_score_mapping = {}\n",
    "\n",
    "    # 検索クエリごとにループ\n",
    "    for docs in retriever_outputs:\n",
    "        # 検索結果のドキュメントごとにループ\n",
    "        for rank, doc in enumerate(docs):\n",
    "            content = doc.page_content\n",
    "\n",
    "            # 初めて登場したコンテンツの場合はスコアを0で初期化\n",
    "            if content not in content_score_mapping:\n",
    "                content_score_mapping[content] = 0\n",
    "\n",
    "            # (1 / (順位 + k)) のスコアを加算\n",
    "            content_score_mapping[content] += 1 / (rank + k)\n",
    "\n",
    "    # スコアの大きい順にソート\n",
    "    ranked = sorted(content_score_mapping.items(), key=lambda x: x[1], reverse=True)  # noqa\n",
    "    return [content for content, _ in ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。LangChainは、開発者がアプリケーションを簡単に構築できるようにすることを目指しており、オープンソースのライブラリやコンポーネント、サードパーティの統合を提供しています。\\n\\nLangChainの主な特徴には以下が含まれます：\\n\\n1. **標準化されたコンポーネントインターフェース**: 様々なAIアプリケーションに必要なコンポーネントのインターフェースを標準化し、異なるプロバイダー間での切り替えを容易にします。\\n\\n2. **オーケストレーション**: 複数のコンポーネントやモデルを組み合わせて複雑なアプリケーションを構築するための効率的な接続を提供します。\\n\\n3. **可観測性と評価**: アプリケーションの動作を理解し、開発の進行を助けるためのトレーシングや評価機能を提供します。\\n\\nLangChainは、以下の主要なライブラリで構成されています：\\n\\n- **`langchain-core`**: 基本的な抽象化とLangChain表現言語（LCEL）。\\n- **`langchain-community`**: サードパーティの統合。\\n- **`langchain`**: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- **[LangGraph](https://langchain-ai.github.io/langgraph)**: LLMを用いた堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- **[LangServe](/docs/langserve)**: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- **[LangSmith](https://docs.smith.langchain.com)**: LLMアプリケーションをデバッグ、テスト、評価、監視するためのプラットフォーム。\\n\\nLangChainは、開発、運用、デプロイの各段階でのサポートを提供し、開発者が自信を持ってアプリケーションを最適化し、展開できるようにします。'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_fusion_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": query_generation_chain | retriever.map() | reciprocal_rank_fusion,\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")  # fmt: skip\n",
    "\n",
    "rag_fusion_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere のリランクモデルを使用する準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab 用なのでコメントアウト\n",
    "# 最初に実行した load_dotenv() で読み込み済みの想定\n",
    "# os.environ[\"COHERE_API_KEY\"] = userdata.get(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvを使っている場合はインストール済み\n",
    "# !pip install langchain-cohere==0.3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohere のリランクモデルの導入\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能があります。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを利用して、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\\n\\n2. **生産化**: LangSmithを使用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\\n\\nLangChainは、以下のオープンソースライブラリで構成されています：\\n- `langchain-core`: 基本的な抽象化とLangChain表現言語。\\n- `langchain-community`: サードパーティの統合。\\n- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するためのプラットフォーム。\\n\\nLangChainは、開発者がアプリケーションを簡単に構築できるようにすることを目指しており、さまざまなコンポーネントを組み合わせて使用することができます。'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_cohere import CohereRerank\n",
    "from langchain_core.documents import Document\n",
    "from typing import Sequence\n",
    "\n",
    "\n",
    "def rerank(inp: dict[str, Any], top_n: int = 3) -> Sequence[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    documents = inp[\"documents\"]\n",
    "\n",
    "    # https://docs.cohere.com/v2/docs/rerank-2\n",
    "    cohere_reranker = CohereRerank(model=\"rerank-multilingual-v3.0\", top_n=top_n)\n",
    "    return cohere_reranker.compress_documents(documents=documents, query=question)\n",
    "\n",
    "\n",
    "rerank_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"documents\": retriever,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=rerank)\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rerank_rag_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5. 複数の Retriever を使う工夫\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM によるルーティング\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
    "\n",
    "langchain_document_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"langchain_document_retriever\"}\n",
    ")  # fmt: skip\n",
    "\n",
    "web_retriever = TavilySearchAPIRetriever(k=3).with_config(\n",
    "    {\"run_name\": \"web_retriever\"}\n",
    ")  # fmt: skip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Route(str, Enum):\n",
    "    langchain_document = \"langchain_document\"\n",
    "    web = \"web\"\n",
    "\n",
    "\n",
    "class RouteOutput(BaseModel):\n",
    "    route: Route\n",
    "\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_template(\"\"\"\\\n",
    "質問に回答するために適切なRetrieverを選択してください。\n",
    "\n",
    "質問: {question}\n",
    "\"\"\")\n",
    "\n",
    "route_chain = (\n",
    "    route_prompt\n",
    "    | model.with_structured_output(RouteOutput)\n",
    "    | (lambda x: x.route)\n",
    ")  # fmt: skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routed_retriever(inp: dict[str, Any]) -> list[Document]:\n",
    "    question = inp[\"question\"]\n",
    "    route = inp[\"route\"]\n",
    "\n",
    "    if route == Route.langchain_document:\n",
    "        return langchain_document_retriever.invoke(question)\n",
    "    elif route == Route.web:\n",
    "        return web_retriever.invoke(question)\n",
    "\n",
    "    raise ValueError(f\"Unknown retriever: {retriever}\")\n",
    "\n",
    "\n",
    "route_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"route\": route_chain,\n",
    "    }\n",
    "    | RunnablePassthrough.assign(context=routed_retriever)\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能を提供しています。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを使用して、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\\n\\n2. **生産化**: LangSmithを使用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\\n\\nLangChainは、以下のオープンソースライブラリで構成されています：\\n- `langchain-core`: 基本的な抽象化とLangChain表現言語（LCEL）。\\n- `langchain-community`: サードパーティの統合。\\n- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するための開発者プラットフォーム。\\n\\nLangChainは、Pythonライブラリに焦点を当てており、JavaScript用のドキュメントも提供されています。'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'文脈には具体的な今日の天気の詳細は記載されていませんが、東京の天気予報に関する情報が含まれています。具体的な天気情報を知りたい場合は、提供されたリンク（例えば、Yahoo!天気や日本気象協会のサイト）を参照してください。'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "route_rag_chain.invoke(\"東京の今日の天気は？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ハイブリッド検索の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uvを使っている場合はインストール済み\n",
    "# !pip install rank-bm25==0.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "\n",
    "chroma_retriever = retriever.with_config(\n",
    "    {\"run_name\": \"chroma_retriever\"}\n",
    ")  # fmt: skip\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(documents).with_config(\n",
    "    {\"run_name\": \"bm25_retriever\"}\n",
    ")  # fmt: skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "hybrid_retriever = (\n",
    "    RunnableParallel(\n",
    "        {\n",
    "            \"chroma_documents\": chroma_retriever,\n",
    "            \"bm25_documents\": bm25_retriever,\n",
    "        }\n",
    "    )\n",
    "    | (lambda x: [x[\"chroma_documents\"], x[\"bm25_documents\"]])\n",
    "    | reciprocal_rank_fusion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能があります。\\n\\n1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを使用して、状態を持つエージェントを構築することも可能です。\\n\\n2. **生産化**: LangSmithを利用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\\n\\n3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\\n\\nLangChainは、以下のオープンソースライブラリで構成されています：\\n- `langchain-core`: 基本的な抽象化とLangChain表現言語（LCEL）。\\n- `langchain-community`: サードパーティの統合。\\n- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\\n- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\\n- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\\n- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するためのプラットフォーム。\\n\\nLangChainは、開発者がアプリケーションを簡単に構築できるようにすることを目指しており、さまざまなコンポーネントを組み合わせて使用することができます。'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_rag_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": hybrid_retriever,\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "hybrid_rag_chain.invoke(\"LangChainの概要を教えて\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
