{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. LangSmith を使った RAG アプリケーションの評価\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-28T02:32:34.489407Z",
     "iopub.status.busy": "2024-06-28T02:32:34.488775Z",
     "iopub.status.idle": "2024-06-28T02:32:34.491583Z",
     "shell.execute_reply": "2024-06-28T02:32:34.491086Z"
    }
   },
   "outputs": [],
   "source": [
    "# google colab 用なのでコメントアウト\n",
    "# import os\n",
    "# from google.colab import userdata\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4. Ragas による合成テストデータの生成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パッケージのインストール\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google colab 用なのでコメントアウト\n",
    "# uv pyproject.toml で chap07以外用の dependencies をコメントアウトして、\n",
    "# chap07用の dependencies をコメントインして、 `uv sync` して下さい。\n",
    "# !pip install langchain-core==0.2.30 langchain-openai==0.1.21 \\\n",
    "#     langchain-community==0.2.12 GitPython==3.1.43 \\\n",
    "#     langchain-chroma==0.1.2 chromadb==0.5.3 \\\n",
    "#     ragas==0.1.14 nest-asyncio==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# 事前に .env ファイルを作って、OPENAI_API_KEY, LANGCHAIN_ENDPOINT, などを設定してください\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索対象のドキュメントのロード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import GitLoader\n",
    "\n",
    "\n",
    "def file_filter(file_path: str) -> bool:\n",
    "    return file_path.endswith(\".mdx\")\n",
    "\n",
    "\n",
    "loader = GitLoader(\n",
    "    clone_url=\"https://github.com/langchain-ai/langchain\",\n",
    "    repo_path=\"./langchain\",\n",
    "    branch=\"master\",\n",
    "    file_filter=file_filter,\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ragas による合成テストデータ生成の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    document.metadata[\"filename\"] = document.metadata[\"source\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'docs/docs/integrations/retrievers/self_query/index.mdx',\n",
       " 'file_path': 'docs/docs/integrations/retrievers/self_query/index.mdx',\n",
       " 'file_name': 'index.mdx',\n",
       " 'file_type': '.mdx',\n",
       " 'filename': 'docs/docs/integrations/retrievers/self_query/index.mdx'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filename と言いつつ、checkout した langchain リポジトリの top directory からの相対パスが入る.\n",
    "# e.g., docs/docs/integrations/retrievers/self_query/index.mdx\n",
    "# file_name には、ファイル名: index.mdx などが入っている\n",
    "document.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ab32ebf1264878b62da6f7c1e0c45b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/1150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76760da852d246af9f65169a5605e11d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm=ChatOpenAI(model=\"gpt-4o-mini\"),  # きちんと評価したい場合は、gpt-4o, o1-mini, o1-preview を推奨\n",
    "    critic_llm=ChatOpenAI(model=\"gpt-4o-mini\"),  # きちんと評価したい場合は、gpt-4o, o1-mini, o1-preview を推奨\n",
    "    embeddings=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(\n",
    "    documents,\n",
    "    test_size=4,\n",
    "    distributions={simple: 0.5, reasoning: 0.25, multi_context: 0.25},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is CerebriumAI and what services does it ...</td>\n",
       "      <td>[# CerebriumAI\\n\\n&gt;[Cerebrium](https://docs.ce...</td>\n",
       "      <td>CerebriumAI is a serverless GPU infrastructure...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the purpose of LLM observability in th...</td>\n",
       "      <td>[# PromptLayer\\n\\n&gt;[PromptLayer](https://docs....</td>\n",
       "      <td>The purpose of LLM observability in the contex...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the perks of AI customizing enterpris...</td>\n",
       "      <td>[# MindsDB\\n\\nMindsDB is the platform for cust...</td>\n",
       "      <td>The perks of AI customizing enterprise data in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What AI features does MindsDB provide with Mot...</td>\n",
       "      <td>[# MindsDB\\n\\nMindsDB is the platform for cust...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{'source': 'docs/docs/integrations/providers/...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  What is CerebriumAI and what services does it ...   \n",
       "1  What is the purpose of LLM observability in th...   \n",
       "2  What are the perks of AI customizing enterpris...   \n",
       "3  What AI features does MindsDB provide with Mot...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [# CerebriumAI\\n\\n>[Cerebrium](https://docs.ce...   \n",
       "1  [# PromptLayer\\n\\n>[PromptLayer](https://docs....   \n",
       "2  [# MindsDB\\n\\nMindsDB is the platform for cust...   \n",
       "3  [# MindsDB\\n\\nMindsDB is the platform for cust...   \n",
       "\n",
       "                                        ground_truth evolution_type  \\\n",
       "0  CerebriumAI is a serverless GPU infrastructure...         simple   \n",
       "1  The purpose of LLM observability in the contex...         simple   \n",
       "2  The perks of AI customizing enterprise data in...      reasoning   \n",
       "3  The answer to given question is not present in...  multi_context   \n",
       "\n",
       "                                            metadata  episode_done  \n",
       "0  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "1  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "2  [{'source': 'docs/docs/integrations/providers/...          True  \n",
       "3  [{'source': 'docs/docs/integrations/providers/...          True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testset の中身を眺めるならどうぞ\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(\"testset.csv\", index=False, encoding=\"utf-8\")\n",
    "testset_df.to_json(\"testset.json\", orient=\"records\", force_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangSmith の Dataset の作成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "dataset_name = \"agent-book\"\n",
    "\n",
    "client = Client()\n",
    "\n",
    "if client.has_dataset(dataset_name=dataset_name):\n",
    "    client.delete_dataset(dataset_name=dataset_name)\n",
    "\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 合成テストデータの保存\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "metadatas = []\n",
    "\n",
    "for testset_record in testset.test_data:\n",
    "    inputs.append(\n",
    "        {\n",
    "            \"question\": testset_record.question,\n",
    "        }\n",
    "    )\n",
    "    outputs.append(\n",
    "        {\n",
    "            \"contexts\": testset_record.contexts,\n",
    "            \"ground_truth\": testset_record.ground_truth,\n",
    "        }\n",
    "    )\n",
    "    metadatas.append(\n",
    "        {\n",
    "            \"source\": testset_record.metadata[0][\"source\"],\n",
    "            \"evolution_type\": testset_record.evolution_type,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.create_examples(\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    metadata=metadatas,\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5. LangSmith と Ragas を使ったオフライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタム Evaluator の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.language_models import BaseChatModel\n",
    "from langsmith.schemas import Example, Run\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics.base import Metric, MetricWithEmbeddings, MetricWithLLM\n",
    "\n",
    "\n",
    "class RagasMetricEvaluator:\n",
    "    def __init__(self, metric: Metric, llm: BaseChatModel, embeddings: Embeddings):\n",
    "        self.metric = metric\n",
    "\n",
    "        # LLMとEmbeddingsをMetricに設定\n",
    "        if isinstance(self.metric, MetricWithLLM):\n",
    "            self.metric.llm = LangchainLLMWrapper(llm)\n",
    "        if isinstance(self.metric, MetricWithEmbeddings):\n",
    "            self.metric.embeddings = LangchainEmbeddingsWrapper(embeddings)\n",
    "\n",
    "    def evaluate(self, run: Run, example: Example) -> dict[str, Any]:\n",
    "        context_strs = [doc.page_content for doc in run.outputs[\"contexts\"]]\n",
    "\n",
    "        # Ragasの評価メトリクスのscoreメソッドでスコアを算出\n",
    "        score = self.metric.score(\n",
    "            {\n",
    "                \"question\": example.inputs[\"question\"],\n",
    "                \"answer\": run.outputs[\"answer\"],\n",
    "                \"contexts\": context_strs,\n",
    "                \"ground_truth\": example.outputs[\"ground_truth\"],\n",
    "            },\n",
    "        )\n",
    "        return {\"key\": self.metric.name, \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from ragas.metrics import answer_relevancy, context_precision\n",
    "\n",
    "metrics = [context_precision, answer_relevancy]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # きちんと評価したい場合は、gpt-4o, o1-mini, o1-preview を推奨\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "evaluators = [RagasMetricEvaluator(metric, llm, embeddings).evaluate for metric in metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推論の関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "db = Chroma.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "''')\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = RunnableParallel(\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever,\n",
    "    }\n",
    ").assign(answer=prompt | model | StrOutputParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(inputs: dict[str, Any]) -> dict[str, Any]:\n",
    "    question = inputs[\"question\"]\n",
    "    output = chain.invoke(question)\n",
    "    return {\n",
    "        \"contexts\": output[\"context\"],\n",
    "        \"answer\": output[\"answer\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### オフライン評価の実装・実行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "evaluate(\n",
    "    predict,\n",
    "    data=\"agent-book\",\n",
    "    evaluators=evaluators,  # type: ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the evaluation results for experiment: 'helpful-lunch-68' at:\n",
    "\n",
    "https://smith.langchain.com/o/xxxxxxx\n",
    "\n",
    "みたいに出力されます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangSmith を使ったオンライン評価の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示する関数の実装\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from langsmith import Client\n",
    "\n",
    "\n",
    "def display_feedback_buttons(run_id: UUID) -> None:\n",
    "    # GoodボタンとBadボタンを準備\n",
    "    good_button = widgets.Button(\n",
    "        description=\"Good\",\n",
    "        button_style=\"success\",\n",
    "        icon=\"thumbs-up\",\n",
    "    )\n",
    "    bad_button = widgets.Button(\n",
    "        description=\"Bad\",\n",
    "        button_style=\"danger\",\n",
    "        icon=\"thumbs-down\",\n",
    "    )\n",
    "\n",
    "    # クリックされた際に実行される関数を定義\n",
    "    def on_button_clicked(button: widgets.Button) -> None:\n",
    "        if button == good_button:\n",
    "            score = 1\n",
    "        elif button == bad_button:\n",
    "            score = 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown button: {button}\")\n",
    "\n",
    "        client = Client()\n",
    "        client.create_feedback(run_id=run_id, key=\"thumbs\", score=score)\n",
    "        print(\"フィードバックを送信しました\")\n",
    "\n",
    "    # ボタンがクリックされた際にon_button_clicked関数を実行\n",
    "    good_button.on_click(on_button_clicked)\n",
    "    bad_button.on_click(on_button_clicked)\n",
    "\n",
    "    # ボタンを表示\n",
    "    display(good_button, bad_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### フィードバックボタンを表示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChainは、大規模言語モデル（LLM）を活用したアプリケーションを開発するためのフレームワークです。このフレームワークは、LLMアプリケーションのライフサイクルの各段階を簡素化します。具体的には、以下のような機能を提供しています。\n",
      "\n",
      "1. **開発**: LangChainのオープンソースのビルディングブロックやコンポーネント、サードパーティの統合を使用してアプリケーションを構築できます。また、LangGraphを使用して、状態を持つエージェントを構築し、ストリーミングや人間の介入をサポートします。\n",
      "\n",
      "2. **生産化**: LangSmithを使用して、チェーンを検査、監視、評価し、継続的に最適化して自信を持ってデプロイできます。\n",
      "\n",
      "3. **デプロイ**: LangGraphアプリケーションを生産準備が整ったAPIやアシスタントに変換することができます。\n",
      "\n",
      "LangChainは、以下のオープンソースライブラリで構成されています：\n",
      "- `langchain-core`: 基本的な抽象化とLangChain表現言語。\n",
      "- `langchain-community`: サードパーティの統合。\n",
      "- `langchain`: アプリケーションの認知アーキテクチャを構成するチェーン、エージェント、検索戦略。\n",
      "- LangGraph: LLMを使用して堅牢で状態を持つマルチアクターアプリケーションを構築するためのライブラリ。\n",
      "- LangServe: LangChainチェーンをREST APIとしてデプロイするためのツール。\n",
      "- LangSmith: LLMアプリケーションをデバッグ、テスト、評価、監視するための開発者プラットフォーム。\n",
      "\n",
      "LangChainは、PythonとJavaScriptの両方のライブラリがあり、特にPythonのLangChainライブラリに焦点を当てたドキュメントが提供されています。\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be60926a374a43d9af490c03f30ee9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Good', icon='thumbs-up', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "113562ffb3bd418195ab9f3fbf93602e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='danger', description='Bad', icon='thumbs-down', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n",
      "フィードバックを送信しました\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tracers.context import collect_runs\n",
    "\n",
    "# LangSmithのトレースのID(Run ID)を取得するため、collect_runs関数を使用\n",
    "with collect_runs() as runs_cb:\n",
    "    output = chain.invoke(\"LangChainの概要を教えて\")\n",
    "    print(output[\"answer\"])\n",
    "    run_id = runs_cb.traced_runs[0].id\n",
    "\n",
    "display_feedback_buttons(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全部実行し終わって、他の章に進む場合は、\n",
    "\n",
    "1. chap07用の dependencies をコメントアウトして、\n",
    "2. juv pyproject.toml で chap07以外用の dependencies をコメントインして、\n",
    "3. `uv sync` するのを忘れないで下さい。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
